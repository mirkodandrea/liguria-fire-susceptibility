{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (28,10)\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_100m'\n",
    "\n",
    "dem_file            = f'{data_dir}/dem.tif'\n",
    "slope_file          = f'{data_dir}/slope.tif'\n",
    "aspect_file         = f'{data_dir}/aspect.tif'\n",
    "northing_file       = f'{data_dir}/northing.tif'\n",
    "easting_file        = f'{data_dir}/easting.tif'\n",
    "\n",
    "urban_distance_file = f'{data_dir}/Urbano.tiff'\n",
    "roads_distance_file = f'{data_dir}/Strade.tiff'\n",
    "crops_distance_file = f'{data_dir}/Coltivo.tiff'\n",
    "\n",
    "vegetation_agg_file = f'{data_dir}/vegetation_agg.tiff'\n",
    "vegetation_file     = f'{data_dir}/vegetation.tiff'\n",
    "\n",
    "fires_shp           = 'shapefiles/perimetrazioni_1997_2017.shp'\n",
    "vegetation_shp      = 'shapefiles/tipiforestali_usosuolo_ctr_fv.shp'\n",
    "roads_shp      = 'shapefiles/Tratte_stradali.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dem file data_100m/dem.tif\n"
     ]
    }
   ],
   "source": [
    "with rio.open(dem_file) as src:\n",
    "    print(f'Reading dem file {dem_file}')\n",
    "    dem = src.read(1)\n",
    "    dem[dem <= -9999] = np.NaN\n",
    "_, dx, _, _, _, dy = src.transform.to_gdal()    \n",
    "bbox = src.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from rasterio import features\n",
    "\n",
    "from shapely.geometry import Point, GeometryCollection\n",
    "\n",
    "def extract_coordinates(indices, src):\n",
    "    indices_t = indices.T[::-1, :]\n",
    "\n",
    "    coordinates = np.stack(src.transform * indices_t)\n",
    "\n",
    "    _, dx, _, _, _, dy = src.transform.to_gdal()\n",
    "    coordinates = coordinates + np.array([[dx, dy]]).T/2\n",
    "\n",
    "    #points = [Point(*p) for p in coordinates.T]\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def encode_feature(gdf, column):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(gdf[column])\n",
    "    encoded_column = encoder.transform(gdf[column])\n",
    "    mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_,))\n",
    "    return encoded_column, mapping\n",
    "\n",
    "\n",
    "def rasterize_numerical_feature(gdf, column, reference_file):\n",
    "    with rio.open(reference_file) as f:\n",
    "        out = f.read(1)\n",
    "        out_array = np.empty(out.shape)\n",
    "        # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "        shapes = ((geom,value) for geom, value in zip(gdf.geometry, gdf[column]))\n",
    "\n",
    "        burned = features.rasterize(shapes=shapes, fill=np.NaN, out=out_array, transform=f.transform)\n",
    "    #    out.write_band(1, burned)\n",
    "\n",
    "    return burned\n",
    "\n",
    "def save_raster_as(array, output_file, reference_file, **kwargs):\n",
    "    with rio.open(reference_file) as f:\n",
    "        profile = f.profile\n",
    "        profile.update(**kwargs)\n",
    "\n",
    "        with rio.open(output_file, 'w', **profile) as dst:\n",
    "            dst.write(array.astype(profile['dtype']), 1)\n",
    "            \n",
    "def read_tiff(tiff_file):\n",
    "    with rio.open(tiff_file) as f:\n",
    "        print(f'Reading file {tiff_file}')        \n",
    "        data = f.read(1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_box_grid(bbox, dx, dy, box_dim):\n",
    "    lon_min, lon_max, lon_step = bbox.left   +dx/2 + box_dim/2, bbox.right +dx/2 - box_dim/2, box_dim\n",
    "    lat_min, lat_max, lat_step = bbox.bottom +dy/2 + box_dim/2, bbox.top   +dy/2 - box_dim/2, box_dim\n",
    "    return lon_min, lon_max, lon_step, lat_min, lat_max, lat_step\n",
    "\n",
    "\n",
    "def build_boxes(lon_min, lon_max, lon_step, lat_min, lat_max, lat_step):\n",
    "    box_lon = np.arange(lon_min, lon_max +lon_step/2, lon_step)\n",
    "    box_lat = np.arange(lat_min, lat_max +lat_step/2, lat_step)\n",
    "    box_lons, box_lats = np.meshgrid(box_lon, box_lat)\n",
    "\n",
    "    return box_lons, box_lats\n",
    "    \n",
    "def get_boxes_rc(coordinates, lon_min, lon_step, lat_min, lat_step):\n",
    "    C = (np.round((coordinates[0, :] - lon_min) / lon_step)).astype('int')\n",
    "    R = (np.round((coordinates[1, :] - lat_min) / lat_step)).astype('int')\n",
    "    RC = np.array((R, C))\n",
    "    return RC\n",
    "\n",
    "def calculate_box_intersections(selected_features, box_lons, box_lats, RC):\n",
    "    unique_rc = np.unique(RC, axis=1)\n",
    "\n",
    "    box_cuts = {}\n",
    "    bar = ProgressBar()\n",
    "    for rc in bar(unique_rc.T):\n",
    "        lon, lat = box_lons[rc[0], rc[1]], box_lats[rc[0], rc[1]]\n",
    "        box = Point(lon, lat).buffer(box_dim + buffer_dim).envelope\n",
    "        box_cut = [box.intersection(g) for g in selected_features.geometry]\n",
    "        box_cuts[(rc[0], rc[1])] = box_cut\n",
    "    \n",
    "    return box_cuts\n",
    "\n",
    "def calculate_distances_on_boxes(coordinates, RC, box_cuts, outside_value=-9999):\n",
    "    bar = ProgressBar()\n",
    "    distances = []\n",
    "    points = []\n",
    "    for p, rc in bar(zip(coordinates.T, RC.T)):\n",
    "        point = Point(*p)\n",
    "        p_distances = [\n",
    "            point.distance(g) \n",
    "            if not g.is_empty \n",
    "            else np.NaN \n",
    "            for g in box_cuts[(rc[0], rc[1])]\n",
    "        ] \n",
    "        d = np.nanmin(p_distances)\n",
    "        d = outside_value if d > buffer_dim else d\n",
    "        distances.append(d)\n",
    "        points.append(point)\n",
    "        \n",
    "    return distances, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dem file data_100m/dem.tif\n"
     ]
    }
   ],
   "source": [
    "with rio.open(dem_file) as src:\n",
    "    print(f'Reading dem file {dem_file}')\n",
    "    dem = src.read(1)\n",
    "    dem[dem <= -9999] = np.NaN\n",
    "\n",
    "if not os.path.isfile(slope_file):\n",
    "    print(f'Creating slope file {slope_file}')\n",
    "    gdal.DEMProcessing(slope_file, dem_file, 'slope')\n",
    "\n",
    "    \n",
    "if not os.path.isfile(northing_file) or not os.path.isfile(easting_file):\n",
    "\n",
    "    if not os.path.isfile(aspect_file):\n",
    "        print(f'Creating aspect file {aspect_file}')\n",
    "        gdal.DEMProcessing(aspect_file, dem_file, 'aspect')\n",
    "\n",
    "    with rio.open(aspect_file) as f:\n",
    "        print(f'Calculating northing and easting files')\n",
    "        print(f'Reading aspect file {aspect_file}')\n",
    "        aspect = f.read(1)\n",
    "        aspect[aspect <= -9999] = np.NaN    \n",
    "        northing = np.cos(aspect * np.pi/180.0)\n",
    "        easting = np.sin(aspect * np.pi/180.0)\n",
    "\n",
    "    print(f'Saving northing file {northing_file}')\n",
    "    save_raster_as(northing, northing_file, aspect_file)\n",
    "    print(f'Saving easting file {easting_file}')    \n",
    "    save_raster_as(easting, easting_file, aspect_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Reading vegetation shp {vegetation_shp}')\n",
    "vegetation = gpd.read_file(vegetation_shp)\n",
    "vegetation['encoded_decodifica'], mapping = encode_feature(vegetation, 'Decodifica')    \n",
    "\n",
    "if not os.path.isfile(vegetation_agg_file):\n",
    "    print(f'Rasterizing vegetation')\n",
    "    vegetation_raster = rasterize_numerical_feature(vegetation, 'encoded_decodifica', dem_file)\n",
    "    print(f'Writing vegetation_raster file {vegetation_agg_file}')    \n",
    "    save_raster_as(vegetation_raster, vegetation_file, dem_file)\n",
    "    \n",
    "\n",
    "if not os.path.isfile(vegetation_agg_file):\n",
    "    print(f'Rasterizing vegetation_agg')    \n",
    "    vegetation_agg_raster = rasterize_numerical_feature(vegetation, 'id_agg_fv', dem_file)\n",
    "    print(f'Writing vegetation_agg_raster file {vegetation_agg_file}')\n",
    "    save_raster_as(vegetation_agg_raster, vegetation_agg_file, dem_file)\n",
    "    \n",
    "if not os.path.isfile(vegetation_agg_file):\n",
    "    print(f'Rasterizing vegetation_agg')    \n",
    "    vegetation_agg_raster = rasterize_numerical_feature(vegetation, 'id_agg_fv', dem_file)\n",
    "    print(f'Writing vegetation_agg_raster file {vegetation_agg_file}')\n",
    "    save_raster_as(vegetation_agg_raster, vegetation_agg_file, dem_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dim = 10000.0\n",
    "buffer_dim = 3000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_types = 'Coltivo', 'Urbano'\n",
    "\n",
    "for distance_type in distance_types:\n",
    "    distance_file = f'{data_dir}/{distance_type}.tiff'\n",
    "\n",
    "    if not os.path.isfile(distance_file):\n",
    "        if mask is None:\n",
    "            vegetation_agg_raster = read_tiff(vegetation_agg_file)\n",
    "            mask = vegetation_agg_raster >= 20\n",
    "            indices = np.argwhere(mask)\n",
    "            coordinates = extract_coordinates(indices, src)\n",
    "        \n",
    "        print(f'Calculating distance {distance_type}')        \n",
    "        selected_features = vegetation.query(f'{distance_type} == 1')\n",
    "\n",
    "        lon_min, lon_max, lon_step, lat_min, lat_max, lat_step = calculate_box_grid(bbox, dx, dy, box_dim)\n",
    "        box_lons, box_lats = build_boxes(lon_min, lon_max, lon_step, lat_min, lat_max, lat_step)\n",
    "        RC = get_boxes_rc(coordinates, lon_min, lon_step, lat_min, lat_step)\n",
    "        box_cuts = calculate_box_intersections(selected_features, box_lons, box_lats, RC)\n",
    "\n",
    "        distances, points = calculate_distances_on_boxes(coordinates, RC, box_cuts)\n",
    "\n",
    "        data = np.empty_like(dem)\n",
    "        data[mask] = distances\n",
    "        \n",
    "        print(f'Writing distance file {distance_file}')\n",
    "        save_raster_as(data, distance_file, dem_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Reading roads shp {roads_shp}')\n",
    "roads = gpd.read_file(roads_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (93 of 93) |########################| Elapsed Time: 0:03:36 Time:  0:03:36\n",
      "- |                                           #   | 21301 Elapsed Time: 0:48:19"
     ]
    }
   ],
   "source": [
    "lon_min, lon_max, lon_step, lat_min, lat_max, lat_step = calculate_box_grid(bbox, dx, dy, box_dim)\n",
    "box_lons, box_lats = build_boxes(lon_min, lon_max, lon_step, lat_min, lat_max, lat_step)\n",
    "RC = get_boxes_rc(coordinates, lon_min, lon_step, lat_min, lat_step)\n",
    "box_cuts = calculate_box_intersections(roads, box_lons, box_lats, RC)\n",
    "\n",
    "distances, points = calculate_distances_on_boxes(coordinates, RC, box_cuts)\n",
    "\n",
    "roads_distance = np.empty_like(dem)\n",
    "roads_distance[mask] = roads_distance\n",
    "\n",
    "print(f'Writing distance file {roads_distance_file}')\n",
    "save_raster_as(roads_distance, roads_distance_file, dem_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIG</th>\n",
       "      <th>ORIGINE</th>\n",
       "      <th>TP_TRA</th>\n",
       "      <th>TIPO_TRATT</th>\n",
       "      <th>SED</th>\n",
       "      <th>SEDE</th>\n",
       "      <th>PERCFITTIZ</th>\n",
       "      <th>PERCORSO_F</th>\n",
       "      <th>STAT</th>\n",
       "      <th>STATO</th>\n",
       "      <th>CLTECFUN</th>\n",
       "      <th>CLASS_TECN</th>\n",
       "      <th>SOTTOPASSO</th>\n",
       "      <th>ID_SEDE</th>\n",
       "      <th>CLASS_MAX_</th>\n",
       "      <th>COD_ENTE_G</th>\n",
       "      <th>COD_STRADA</th>\n",
       "      <th>ID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da CTR</td>\n",
       "      <td>2</td>\n",
       "      <td>tratto di strada indifferenziata</td>\n",
       "      <td>1</td>\n",
       "      <td>propria</td>\n",
       "      <td>1</td>\n",
       "      <td>tratto di effettiva percorrenza veicolare</td>\n",
       "      <td>F</td>\n",
       "      <td>In esercizio</td>\n",
       "      <td>1</td>\n",
       "      <td>autostrada</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>148601</td>\n",
       "      <td>LINESTRING Z (1395231.66999714 4850846.7013805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da CTR</td>\n",
       "      <td>2</td>\n",
       "      <td>tratto di strada indifferenziata</td>\n",
       "      <td>1</td>\n",
       "      <td>su ponte, viadotto</td>\n",
       "      <td>2</td>\n",
       "      <td>tratto di effettiva percorrenza veicolare</td>\n",
       "      <td>F</td>\n",
       "      <td>In esercizio</td>\n",
       "      <td>1</td>\n",
       "      <td>autostrada</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>148701</td>\n",
       "      <td>LINESTRING Z (1394958.63999709 4850636.7013803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da CTR</td>\n",
       "      <td>2</td>\n",
       "      <td>tratto di strada indifferenziata</td>\n",
       "      <td>1</td>\n",
       "      <td>propria</td>\n",
       "      <td>1</td>\n",
       "      <td>tratto di effettiva percorrenza veicolare</td>\n",
       "      <td>F</td>\n",
       "      <td>In esercizio</td>\n",
       "      <td>1</td>\n",
       "      <td>autostrada</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>148801</td>\n",
       "      <td>LINESTRING Z (1405608.84999862 4855309.1013848...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>da CTR</td>\n",
       "      <td>2</td>\n",
       "      <td>tratto di strada indifferenziata</td>\n",
       "      <td>1</td>\n",
       "      <td>propria</td>\n",
       "      <td>1</td>\n",
       "      <td>tratto di effettiva percorrenza veicolare</td>\n",
       "      <td>F</td>\n",
       "      <td>In esercizio</td>\n",
       "      <td>1</td>\n",
       "      <td>autostrada</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>111</td>\n",
       "      <td>148901</td>\n",
       "      <td>LINESTRING Z (1405596.95999862 4855299.0013848...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da CTR</td>\n",
       "      <td>2</td>\n",
       "      <td>tratto di strada indifferenziata</td>\n",
       "      <td>1</td>\n",
       "      <td>propria</td>\n",
       "      <td>1</td>\n",
       "      <td>tratto di effettiva percorrenza veicolare</td>\n",
       "      <td>F</td>\n",
       "      <td>In esercizio</td>\n",
       "      <td>1</td>\n",
       "      <td>autostrada</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>149001</td>\n",
       "      <td>LINESTRING Z (1405715.32999863 4855306.0013848...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ORIG ORIGINE                            TP_TRA TIPO_TRATT  \\\n",
       "0  da CTR       2  tratto di strada indifferenziata          1   \n",
       "1  da CTR       2  tratto di strada indifferenziata          1   \n",
       "2  da CTR       2  tratto di strada indifferenziata          1   \n",
       "3  da CTR       2  tratto di strada indifferenziata          1   \n",
       "4  da CTR       2  tratto di strada indifferenziata          1   \n",
       "\n",
       "                  SED SEDE                                 PERCFITTIZ  \\\n",
       "0             propria    1  tratto di effettiva percorrenza veicolare   \n",
       "1  su ponte, viadotto    2  tratto di effettiva percorrenza veicolare   \n",
       "2             propria    1  tratto di effettiva percorrenza veicolare   \n",
       "3             propria    1  tratto di effettiva percorrenza veicolare   \n",
       "4             propria    1  tratto di effettiva percorrenza veicolare   \n",
       "\n",
       "  PERCORSO_F          STAT STATO    CLTECFUN CLASS_TECN SOTTOPASSO ID_SEDE  \\\n",
       "0          F  In esercizio     1  autostrada          1          F    None   \n",
       "1          F  In esercizio     1  autostrada          1          F    None   \n",
       "2          F  In esercizio     1  autostrada          1          F    None   \n",
       "3          F  In esercizio     1  autostrada          1          F    None   \n",
       "4          F  In esercizio     1  autostrada          1          F    None   \n",
       "\n",
       "  CLASS_MAX_ COD_ENTE_G COD_STRADA      ID  \\\n",
       "0       None       None        121  148601   \n",
       "1       None       None        121  148701   \n",
       "2       None       None        121  148801   \n",
       "3       None       None        111  148901   \n",
       "4       None       None        121  149001   \n",
       "\n",
       "                                            geometry  \n",
       "0  LINESTRING Z (1395231.66999714 4850846.7013805...  \n",
       "1  LINESTRING Z (1394958.63999709 4850636.7013803...  \n",
       "2  LINESTRING Z (1405608.84999862 4855309.1013848...  \n",
       "3  LINESTRING Z (1405596.95999862 4855299.0013848...  \n",
       "4  LINESTRING Z (1405715.32999863 4855306.0013848...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading northing file data_100m/slope.tif\n",
      "Reading file data_100m/slope.tif\n",
      "Reading northing file data_100m/northing.tif\n",
      "Reading file data_100m/northing.tif\n",
      "Reading easting file data_100m/easting.tif\n",
      "Reading file data_100m/easting.tif\n",
      "Reading vegetation_raster file data_100m/vegetation.tiff\n",
      "Reading file data_100m/vegetation.tiff\n",
      "Reading vegetation_agg_raster file data_100m/vegetation_agg.tiff\n",
      "Reading file data_100m/vegetation_agg.tiff\n",
      "Reading urban distance file data_100m/Urbano.tiff\n",
      "Reading file data_100m/Urbano.tiff\n",
      "Reading roads distance file data_100m/Strade.tiff\n",
      "Reading file data_100m/Strade.tiff\n",
      "Reading roads distance file data_100m/Coltivo.tiff\n",
      "Reading file data_100m/Coltivo.tiff\n"
     ]
    }
   ],
   "source": [
    "print(f'Reading northing file {slope_file}')\n",
    "slope = read_tiff(slope_file)\n",
    "\n",
    "print(f'Reading northing file {northing_file}')\n",
    "northing = read_tiff(northing_file)\n",
    "    \n",
    "print(f'Reading easting file {easting_file}') \n",
    "easting = read_tiff(easting_file)\n",
    "\n",
    "print(f'Reading vegetation_raster file {vegetation_file}')            \n",
    "vegetation_raster = read_tiff(vegetation_file)\n",
    "    \n",
    "print(f'Reading vegetation_agg_raster file {vegetation_agg_file}')          \n",
    "vegetation_agg_raster = read_tiff(vegetation_agg_file)\n",
    "\n",
    "print(f'Reading urban distance file {urban_distance_file}')\n",
    "urban_distance = read_tiff(urban_distance_file)\n",
    "\n",
    "print(f'Reading roads distance file {roads_distance_file}')\n",
    "roads_distance = read_tiff(roads_distance_file)\n",
    "\n",
    "print(f'Reading roads distance file {crops_distance_file}')\n",
    "crops_distance = read_tiff(crops_distance_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading vegetation shp shapefiles/tipiforestali_usosuolo_ctr_fv.shp\n"
     ]
    }
   ],
   "source": [
    "print(f'Reading vegetation shp {vegetation_shp}')\n",
    "vegetation = gpd.read_file(vegetation_shp)\n",
    "vegetation['encoded_decodifica'], mapping = encode_feature(vegetation, 'Decodifica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking vegetation raster excluding non-vegetated areas\n",
    "mask = (vegetation_agg_raster >= 20) & (dem != -9999) & (slope != -9999) & (northing != -9999) & (easting != -9999)\n",
    "indeces = np.argwhere(mask)\n",
    "coordinates = extract_coordinates(indeces, src)\n",
    "points_geom = [Point(*p) for p in coordinates.T]\n",
    "\n",
    "points = gpd.GeoDataFrame(pd.DataFrame(indeces, columns=['row', 'col']), geometry=points_geom, crs={'init': 'epsg:3003'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_envelopes = points.copy()\n",
    "points_envelopes.geometry = points.geometry.buffer(dx/2).envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading fires shp shapefiles/perimetrazioni_1997_2017.shp\n"
     ]
    }
   ],
   "source": [
    "print(f'Reading fires shp {fires_shp}')\n",
    "fires = gpd.read_file(fires_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_df = gpd.sjoin(points_envelopes, fires)\\\n",
    "             .loc[:, ('row', 'col', 'data', 'anno', 'stagione', 'area_ha')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "absence_idx = ~points.index.isin(presence_df.index)\n",
    "absence_df = points.iloc[points.index[absence_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/DATA_ExFAT/datascience/suscettivita-incendi-liguria/.conda/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Volumes/DATA_ExFAT/datascience/suscettivita-incendi-liguria/.conda/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Volumes/DATA_ExFAT/datascience/suscettivita-incendi-liguria/.conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "presence_df.loc[:, 'fire'] = 1\n",
    "absence_df.loc[:, 'fire'] = 0\n",
    "\n",
    "dataset = pd.concat((presence_df, absence_df), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'dem': dem,\n",
    "    'slope': slope,\n",
    "    'north': northing,\n",
    "    'east': easting,\n",
    "    'veg': vegetation_raster,\n",
    "    'veg_agg': vegetation_agg_raster,\n",
    "    'urban_d': urban_distance,\n",
    "    'roads_d': roads_distance,\n",
    "    'crops_d': crops_distance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data_dict.items():\n",
    "    dataset[k] = v[dataset.row.values, dataset.col.values]\n",
    "    \n",
    "dataset.loc[dataset['north'].isna(), 'north'] = 0\n",
    "dataset.loc[dataset['east'].isna(), 'east'] = 0\n",
    "dataset.loc[dataset['roads_d'].isna(), 'roads_d'] = -9999   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.geometry = points.loc[dataset.index].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_file(f'{data_dir}/dataset.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_csv = dataset.copy()\n",
    "dataset_csv['x'] = dataset_csv.geometry.x\n",
    "dataset_csv['y'] = dataset_csv.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_csv = dataset_csv.drop('geometry', axis=1)\n",
    "dataset_csv.to_csv(f'{data_dir}/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = list(data_dict.keys())\n",
    "variables.remove('veg_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1\n",
    "# create a dataset selecting a sample of points from fire points, then the same amount of absence\n",
    "presence_train_dataset = dataset.query('anno < 2013')\n",
    "presence_test_dataset = dataset.query('anno >= 2013')\n",
    "\n",
    "presence_sample = presence_train_dataset.query('fire == 1').sample(frac=sample_size).loc[:, variables + ['fire']]\n",
    "absence_sample = dataset.query('fire == 0').sample(n=len(presence_sample)).loc[:, variables + ['fire']]\n",
    "\n",
    "train_df = pd.concat((presence_sample, absence_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_test_sample = presence_test_dataset.query('fire == 1').sample(frac=sample_size).loc[:, variables + ['fire']]\n",
    "absence_sample = dataset.query('fire == 0').sample(n=len(presence_sample)).loc[:, variables + ['fire']]\n",
    "\n",
    "test_df = pd.concat((presence_sample, absence_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=8,\n",
       "            oob_score=False, random_state=0, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=100,\n",
    "                             random_state=0, n_jobs=8, verbose=1)\n",
    "\n",
    "\n",
    "clf.fit(train_df[variables], train_df['fire'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6\n",
      "0     slope     north      east       veg   urban_d   roads_d   crops_d\n",
      "1  0.143643  0.144666  0.122167  0.205381  0.133513  0.112417  0.138213\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame([variables, clf.feature_importances_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-7543b0e584bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "# Import tools needed for visualization\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "from IPython.display import Image, display\n",
    "def view_pydot(pdot):\n",
    "    plt = Image(pdot.create_png())\n",
    "    display(plt)\n",
    "    \n",
    "\n",
    "\n",
    "# Pull out one tree from the forest\n",
    "tree = clf.estimators_[5]\n",
    "\n",
    "\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "view_pydot(graph)\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['fire'].values\n",
    "X_train = train_df[variables].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "#instantiate a random forest regressor 'rf'\n",
    "\n",
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "# Split the data into 70% train and 30% test X feature layer, y is the target layer)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 28.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [50, 100, 200], 'max_features': [3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning the hypermarameters of Random forest ; \n",
    "# Define the dictionary 'params_rf'(the values are examples); more parameters to be tuned are readable\n",
    "# using rf.get_params() \n",
    "params_rf = {\n",
    "     'n_estimators': [50, 100, 200],\n",
    "     'max_features': [3, 4, 5],\n",
    "}\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf (rf is an untuned random forest regressor model)\n",
    "# note that n_jobs= -1 remove any restriction on the use of all the CPU cores\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=5,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit the model \n",
    "\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df['fire'].values\n",
    "X_test = test_df[variables].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 0.244\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "                       \n",
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) \n",
    "\n",
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=best_model.feature_importances_,\n",
    "                        index=variables) # add the name of the features, maybe it is in the form data.columns?\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
