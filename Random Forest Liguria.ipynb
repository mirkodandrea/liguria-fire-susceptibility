{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (28,10)\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_100m'\n",
    "\n",
    "dem_file            = f'{data_dir}/dem.tif'\n",
    "slope_file          = f'{data_dir}/slope.tif'\n",
    "aspect_file         = f'{data_dir}/aspect.tif'\n",
    "northing_file       = f'{data_dir}/northing.tif'\n",
    "easting_file        = f'{data_dir}/easting.tif'\n",
    "\n",
    "urban_distance_file = f'{data_dir}/Urbano.tiff'\n",
    "roads_distance_file = f'{data_dir}/Strade.tiff'\n",
    "crops_distance_file = f'{data_dir}/Coltivo.tiff'\n",
    "\n",
    "vegetation_agg_file = f'{data_dir}/vegetation_agg.tiff'\n",
    "vegetation_file     = f'{data_dir}/vegetation.tiff'\n",
    "\n",
    "fires_shp           = 'shapefiles/perimetrazioni_1997_2017.shp'\n",
    "vegetation_shp      = 'shapefiles/tipiforestali_usosuolo_ctr_fv.shp'\n",
    "roads_shp      = 'shapefiles/Tratte_stradali.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dem file data_100m/dem.tif\n"
     ]
    }
   ],
   "source": [
    "with rio.open(dem_file) as src:\n",
    "    print(f'Reading dem file {dem_file}')\n",
    "    dem = src.read(1)\n",
    "    dem[dem <= -9999] = np.NaN\n",
    "_, dx, _, _, _, dy = src.transform.to_gdal()    \n",
    "bbox = src.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from rasterio import features\n",
    "\n",
    "from shapely.geometry import Point, GeometryCollection\n",
    "\n",
    "def extract_coordinates(indices, src):\n",
    "    indices_t = indices.T[::-1, :]\n",
    "\n",
    "    coordinates = np.stack(src.transform * indices_t)\n",
    "\n",
    "    _, dx, _, _, _, dy = src.transform.to_gdal()\n",
    "    coordinates = coordinates + np.array([[dx, dy]]).T/2\n",
    "\n",
    "    #points = [Point(*p) for p in coordinates.T]\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def encode_feature(gdf, column):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(gdf[column])\n",
    "    encoded_column = encoder.transform(gdf[column])\n",
    "    mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_,))\n",
    "    return encoded_column, mapping\n",
    "\n",
    "\n",
    "def rasterize_numerical_feature(gdf, reference_file, column=None):\n",
    "    with rio.open(reference_file) as f:\n",
    "        out = f.read(1)\n",
    "        out_array = np.empty(out.shape)\n",
    "        # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "        if column is not None:\n",
    "            shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[column]))\n",
    "        else:\n",
    "            shapes = ((geom, 1) for geom in gdf.geometry)\n",
    "\n",
    "        burned = features.rasterize(shapes=shapes, fill=np.NaN, out=out_array, transform=f.transform)\n",
    "    #    out.write_band(1, burned)\n",
    "\n",
    "    return burned\n",
    "\n",
    "def save_raster_as(array, output_file, reference_file, **kwargs):\n",
    "    with rio.open(reference_file) as f:\n",
    "        profile = f.profile\n",
    "        profile.update(**kwargs)\n",
    "\n",
    "        with rio.open(output_file, 'w', **profile) as dst:\n",
    "            dst.write(array.astype(profile['dtype']), 1)\n",
    "            \n",
    "def read_tiff(tiff_file):\n",
    "    with rio.open(tiff_file) as f:\n",
    "        print(f'Reading file {tiff_file}')        \n",
    "        data = f.read(1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_box_grid(bbox, dx, dy, box_dim):\n",
    "    lon_min, lon_max, lon_step = bbox.left   +dx/2 + box_dim/2, bbox.right +dx/2 - box_dim/2, box_dim\n",
    "    lat_min, lat_max, lat_step = bbox.bottom +dy/2 + box_dim/2, bbox.top   +dy/2 - box_dim/2, box_dim\n",
    "    return lon_min, lon_max, lon_step, lat_min, lat_max, lat_step\n",
    "\n",
    "\n",
    "def build_boxes(lon_min, lon_max, lon_step, lat_min, lat_max, lat_step):\n",
    "    box_lon = np.arange(lon_min, lon_max +lon_step/2, lon_step)\n",
    "    box_lat = np.arange(lat_min, lat_max +lat_step/2, lat_step)\n",
    "    box_lons, box_lats = np.meshgrid(box_lon, box_lat)\n",
    "\n",
    "    return box_lons, box_lats\n",
    "    \n",
    "def get_boxes_rc(coordinates, lon_min, lon_step, lat_min, lat_step):\n",
    "    C = (np.round((coordinates[0, :] - lon_min) / lon_step)).astype('int')\n",
    "    R = (np.round((coordinates[1, :] - lat_min) / lat_step)).astype('int')\n",
    "    RC = np.array((R, C))\n",
    "    return RC\n",
    "\n",
    "def calculate_box_intersections(geometry, box_lons, box_lats, RC):\n",
    "    unique_rc = np.unique(RC, axis=1)\n",
    "\n",
    "    box_cuts = {}\n",
    "    bar = ProgressBar()\n",
    "    for rc in bar(unique_rc.T):\n",
    "        lon, lat = box_lons[rc[0], rc[1]], box_lats[rc[0], rc[1]]\n",
    "        box = Point(lon, lat).buffer(box_dim + buffer_dim).envelope\n",
    "        box_cut = [box.intersection(g) for g in geometry]\n",
    "        box_cuts[(rc[0], rc[1])] = box_cut\n",
    "    \n",
    "    return box_cuts\n",
    "\n",
    "def calculate_distances_on_boxes(coordinates, RC, box_cuts, outside_value=-9999):\n",
    "    bar = ProgressBar()\n",
    "    distances = []\n",
    "    points = []\n",
    "    for p, rc in bar(zip(coordinates.T, RC.T)):\n",
    "        point = Point(*p)\n",
    "        p_distances = [\n",
    "            point.distance(g) \n",
    "            if not g.is_empty \n",
    "            else np.NaN \n",
    "            for g in box_cuts[(rc[0], rc[1])]\n",
    "        ] \n",
    "        d = np.nanmin(p_distances)\n",
    "        d = outside_value if d > buffer_dim else d\n",
    "        distances.append(d)\n",
    "        points.append(point)\n",
    "        \n",
    "    return distances, points\n",
    "\n",
    "\n",
    "def write_distance_raster(raster_file, dst_file, column=None):\n",
    "    src_ds = gdal.Open(raster_file)\n",
    "    srcband=src_ds.GetRasterBand(1)\n",
    "\n",
    "\n",
    "    drv = gdal.GetDriverByName('GTiff')\n",
    "    dst_ds = drv.Create( dst_file,\n",
    "                         src_ds.RasterXSize, src_ds.RasterYSize, 1,\n",
    "                         gdal.GetDataTypeByName('Float32'))\n",
    "\n",
    "    dst_ds.SetGeoTransform( src_ds.GetGeoTransform() )\n",
    "    dst_ds.SetProjection( src_ds.GetProjectionRef() )\n",
    "\n",
    "    dstband = dst_ds.GetRasterBand(1)\n",
    "    gdal.ComputeProximity(srcband, dstband, [\"DISTUNITS=GEO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dem file data_100m/dem.tif\n"
     ]
    }
   ],
   "source": [
    "with rio.open(dem_file) as src:\n",
    "    print(f'Reading dem file {dem_file}')\n",
    "    dem = src.read(1)\n",
    "    dem[dem <= -9999] = np.NaN\n",
    "\n",
    "if not os.path.isfile(slope_file):\n",
    "    print(f'Creating slope file {slope_file}')\n",
    "    gdal.DEMProcessing(slope_file, dem_file, 'slope')\n",
    "\n",
    "    \n",
    "if not os.path.isfile(northing_file) or not os.path.isfile(easting_file):\n",
    "\n",
    "    if not os.path.isfile(aspect_file):\n",
    "        print(f'Creating aspect file {aspect_file}')\n",
    "        gdal.DEMProcessing(aspect_file, dem_file, 'aspect')\n",
    "\n",
    "    with rio.open(aspect_file) as f:\n",
    "        print(f'Calculating northing and easting files')\n",
    "        print(f'Reading aspect file {aspect_file}')\n",
    "        aspect = f.read(1)\n",
    "        aspect[aspect <= -9999] = np.NaN    \n",
    "        northing = np.cos(aspect * np.pi/180.0)\n",
    "        easting = np.sin(aspect * np.pi/180.0)\n",
    "\n",
    "    print(f'Saving northing file {northing_file}')\n",
    "    save_raster_as(northing, northing_file, aspect_file)\n",
    "    print(f'Saving easting file {easting_file}')    \n",
    "    save_raster_as(easting, easting_file, aspect_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading vegetation shp shapefiles/tipiforestali_usosuolo_ctr_fv.shp\n"
     ]
    }
   ],
   "source": [
    "print(f'Reading vegetation shp {vegetation_shp}')\n",
    "vegetation = gpd.read_file(vegetation_shp)\n",
    "vegetation['encoded_decodifica'], mapping = encode_feature(vegetation, 'Decodifica')    \n",
    "\n",
    "if not os.path.isfile(vegetation_agg_file):\n",
    "    print(f'Rasterizing vegetation')\n",
    "    vegetation_raster = rasterize_numerical_feature(vegetation, dem_file, 'encoded_decodifica')\n",
    "    print(f'Writing vegetation_raster file {vegetation_agg_file}')    \n",
    "    save_raster_as(vegetation_raster, vegetation_file, dem_file)\n",
    "    \n",
    "\n",
    "if not os.path.isfile(vegetation_agg_file):\n",
    "    print(f'Rasterizing vegetation_agg')    \n",
    "    vegetation_agg_raster = rasterize_numerical_feature(vegetation, dem_file, 'id_agg_fv')\n",
    "    print(f'Writing vegetation_agg_raster file {vegetation_agg_file}')\n",
    "    save_raster_as(vegetation_agg_raster, vegetation_agg_file, dem_file)\n",
    "    \n",
    "if not os.path.isfile(vegetation_agg_file):\n",
    "    print(f'Rasterizing vegetation_agg')    \n",
    "    vegetation_agg_raster = rasterize_numerical_feature(vegetation, dem_file, 'id_agg_fv')\n",
    "    print(f'Writing vegetation_agg_raster file {vegetation_agg_file}')\n",
    "    save_raster_as(vegetation_agg_raster, vegetation_agg_file, dem_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dim = 10000.0\n",
    "buffer_dim = 3000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file data_100m/vegetation_agg.tiff\n"
     ]
    }
   ],
   "source": [
    "vegetation_agg_raster = read_tiff(vegetation_agg_file)\n",
    "mask = vegetation_agg_raster >= 20\n",
    "indices = np.argwhere(mask)\n",
    "coordinates = extract_coordinates(indices, src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lon_min, lon_max, lon_step, lat_min, lat_max, lat_step = calculate_box_grid(bbox, dx, dy, box_dim)\n",
    "box_lons, box_lats = build_boxes(lon_min, lon_max, lon_step, lat_min, lat_max, lat_step)\n",
    "RC = get_boxes_rc(coordinates, lon_min, lon_step, lat_min, lat_step)\n",
    "box_cuts = calculate_box_intersections(selected_features, box_lons, box_lats, RC)\n",
    "\n",
    "distances, points = calculate_distances_on_boxes(coordinates, RC, box_cuts)\n",
    "\n",
    "data = np.empty_like(dem)\n",
    "data[mask] = distances\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = vegetation.query(f'Coltivo == 1')\n",
    "crops_raster_file = f'{data_dir}/crops.tiff'\n",
    "crops_raster = rasterize_numerical_feature(crops, dem_file)\n",
    "save_raster_as(crops_raster, crops_raster_file, dem_file)\n",
    "\n",
    "crops_distance_file = f'{data_dir}/crops_distance.tiff'            \n",
    "write_distance_raster(crops_raster_file, crops_distance_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban = vegetation.query(f'Urbano == 1')\n",
    "urban_raster_file = f'{data_dir}/urban.tiff'\n",
    "urban_raster = rasterize_numerical_feature(urban, dem_file)\n",
    "save_raster_as(urban_raster, urban_raster_file, dem_file)\n",
    "\n",
    "urban_distance_file = f'{data_dir}/urban_distance.tiff'            \n",
    "write_distance_raster(urban_raster_file, urban_distance_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading roads shp shapefiles/Tratte_stradali.shp\n"
     ]
    }
   ],
   "source": [
    "print(f'Reading roads shp {roads_shp}')\n",
    "roads = gpd.read_file(roads_shp)\n",
    "\n",
    "roads_raster = rasterize_numerical_feature(roads, dem_file)\n",
    "roads_raster_file = f'{data_dir}/roads.tiff'\n",
    "save_raster_as(roads_raster, roads_raster_file, dem_file)\n",
    "\n",
    "roads_distance_file = f'{data_dir}/roads_distance.tiff'            \n",
    "write_distance_raster(roads_raster_file, roads_distance_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Reading northing file {slope_file}')\n",
    "slope = read_tiff(slope_file)\n",
    "\n",
    "print(f'Reading northing file {northing_file}')\n",
    "northing = read_tiff(northing_file)\n",
    "    \n",
    "print(f'Reading easting file {easting_file}') \n",
    "easting = read_tiff(easting_file)\n",
    "\n",
    "print(f'Reading vegetation_raster file {vegetation_file}')            \n",
    "vegetation_raster = read_tiff(vegetation_file)\n",
    "    \n",
    "print(f'Reading vegetation_agg_raster file {vegetation_agg_file}')          \n",
    "vegetation_agg_raster = read_tiff(vegetation_agg_file)\n",
    "\n",
    "print(f'Reading urban distance file {urban_distance_file}')\n",
    "urban_distance = read_tiff(urban_distance_file)\n",
    "\n",
    "print(f'Reading roads distance file {roads_distance_file}')\n",
    "roads_distance = read_tiff(roads_distance_file)\n",
    "\n",
    "print(f'Reading roads distance file {crops_distance_file}')\n",
    "crops_distance = read_tiff(crops_distance_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading vegetation shp shapefiles/tipiforestali_usosuolo_ctr_fv.shp\n"
     ]
    }
   ],
   "source": [
    "print(f'Reading vegetation shp {vegetation_shp}')\n",
    "vegetation = gpd.read_file(vegetation_shp)\n",
    "vegetation['encoded_decodifica'], mapping = encode_feature(vegetation, 'Decodifica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking vegetation raster excluding non-vegetated areas\n",
    "mask = (vegetation_agg_raster >= 20) & (dem != -9999) & (slope != -9999) & (northing != -9999) & (easting != -9999)\n",
    "indeces = np.argwhere(mask)\n",
    "coordinates = extract_coordinates(indeces, src)\n",
    "points_geom = [Point(*p) for p in coordinates.T]\n",
    "\n",
    "points = gpd.GeoDataFrame(pd.DataFrame(indeces, columns=['row', 'col']), geometry=points_geom, crs={'init': 'epsg:3003'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_envelopes = points.copy()\n",
    "points_envelopes.geometry = points.geometry.buffer(dx/2).envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading fires shp shapefiles/perimetrazioni_1997_2017.shp\n"
     ]
    }
   ],
   "source": [
    "print(f'Reading fires shp {fires_shp}')\n",
    "fires = gpd.read_file(fires_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_df = gpd.sjoin(points_envelopes, fires)\\\n",
    "             .loc[:, ('row', 'col', 'data', 'anno', 'stagione', 'area_ha')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "absence_idx = ~points.index.isin(presence_df.index)\n",
    "absence_df = points.iloc[points.index[absence_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/DATA_ExFAT/datascience/suscettivita-incendi-liguria/.conda/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Volumes/DATA_ExFAT/datascience/suscettivita-incendi-liguria/.conda/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Volumes/DATA_ExFAT/datascience/suscettivita-incendi-liguria/.conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "presence_df.loc[:, 'fire'] = 1\n",
    "absence_df.loc[:, 'fire'] = 0\n",
    "\n",
    "dataset = pd.concat((presence_df, absence_df), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'dem': dem,\n",
    "    'slope': slope,\n",
    "    'north': northing,\n",
    "    'east': easting,\n",
    "    'veg': vegetation_raster,\n",
    "    'veg_agg': vegetation_agg_raster,\n",
    "    'urban_d': urban_distance,\n",
    "    'roads_d': roads_distance,\n",
    "    'crops_d': crops_distance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data_dict.items():\n",
    "    dataset[k] = v[dataset.row.values, dataset.col.values]\n",
    "    \n",
    "dataset.loc[dataset['north'].isna(), 'north'] = 0\n",
    "dataset.loc[dataset['east'].isna(), 'east'] = 0\n",
    "dataset.loc[dataset['roads_d'].isna(), 'roads_d'] = -9999   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.geometry = points.loc[dataset.index].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_file(f'{data_dir}/dataset.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_csv = dataset.copy()\n",
    "dataset_csv['x'] = dataset_csv.geometry.x\n",
    "dataset_csv['y'] = dataset_csv.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_csv = dataset_csv.drop('geometry', axis=1)\n",
    "dataset_csv.to_csv(f'{data_dir}/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = list(data_dict.keys())\n",
    "variables.remove('veg_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1\n",
    "# create a dataset selecting a sample of points from fire points, then the same amount of absence\n",
    "presence_train_dataset = dataset.query('anno < 2013')\n",
    "presence_test_dataset = dataset.query('anno >= 2013')\n",
    "\n",
    "presence_sample = presence_train_dataset.query('fire == 1').sample(frac=sample_size).loc[:, variables + ['fire']]\n",
    "absence_sample = dataset.query('fire == 0').sample(n=len(presence_sample)).loc[:, variables + ['fire']]\n",
    "\n",
    "train_df = pd.concat((presence_sample, absence_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_test_sample = presence_test_dataset.query('fire == 1').sample(frac=sample_size).loc[:, variables + ['fire']]\n",
    "absence_sample = dataset.query('fire == 0').sample(n=len(presence_sample)).loc[:, variables + ['fire']]\n",
    "\n",
    "test_df = pd.concat((presence_sample, absence_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=8,\n",
       "            oob_score=False, random_state=0, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=100,\n",
    "                             random_state=0, n_jobs=8, verbose=1)\n",
    "\n",
    "\n",
    "clf.fit(train_df[variables], train_df['fire'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6\n",
      "0     slope     north      east       veg   urban_d   roads_d   crops_d\n",
      "1  0.143643  0.144666  0.122167  0.205381  0.133513  0.112417  0.138213\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame([variables, clf.feature_importances_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-7543b0e584bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "# Import tools needed for visualization\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "from IPython.display import Image, display\n",
    "def view_pydot(pdot):\n",
    "    plt = Image(pdot.create_png())\n",
    "    display(plt)\n",
    "    \n",
    "\n",
    "\n",
    "# Pull out one tree from the forest\n",
    "tree = clf.estimators_[5]\n",
    "\n",
    "\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "view_pydot(graph)\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['fire'].values\n",
    "X_train = train_df[variables].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "#instantiate a random forest regressor 'rf'\n",
    "\n",
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "# Split the data into 70% train and 30% test X feature layer, y is the target layer)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 28.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [50, 100, 200], 'max_features': [3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning the hypermarameters of Random forest ; \n",
    "# Define the dictionary 'params_rf'(the values are examples); more parameters to be tuned are readable\n",
    "# using rf.get_params() \n",
    "params_rf = {\n",
    "     'n_estimators': [50, 100, 200],\n",
    "     'max_features': [3, 4, 5],\n",
    "}\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf (rf is an untuned random forest regressor model)\n",
    "# note that n_jobs= -1 remove any restriction on the use of all the CPU cores\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=5,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit the model \n",
    "\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df['fire'].values\n",
    "X_test = test_df[variables].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 0.244\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "                       \n",
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) \n",
    "\n",
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=best_model.feature_importances_,\n",
    "                        index=variables) # add the name of the features, maybe it is in the form data.columns?\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
